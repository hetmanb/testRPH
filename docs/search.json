[
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "R for Public Health",
    "section": "",
    "text": "This is the readme for tdu-rph"
  },
  {
    "objectID": "module02.html",
    "href": "module02.html",
    "title": "Module 2",
    "section": "",
    "text": "Welcome back!\nThis page will hold the materials required to complete the Sea Shanty activity."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to R for Public Health (RPH)",
    "section": "",
    "text": "Review and prepare the ship’s manifest provided to you by the steward.\nSea shanty\nIllness linelist and manifest. Combine to identify additional details.\nFood exposure linelist - create tables and attack rates / OR\nEpi curve - is the outbreak over?\nFaceting / epi curve + crew manifest"
  },
  {
    "objectID": "index.html#overview-of-the-course",
    "href": "index.html#overview-of-the-course",
    "title": "Welcome to R for Public Health (RPH)",
    "section": "",
    "text": "Review and prepare the ship’s manifest provided to you by the steward.\nSea shanty\nIllness linelist and manifest. Combine to identify additional details.\nFood exposure linelist - create tables and attack rates / OR\nEpi curve - is the outbreak over?\nFaceting / epi curve + crew manifest"
  },
  {
    "objectID": "index.html#preamble-setting-up-your-workspace",
    "href": "index.html#preamble-setting-up-your-workspace",
    "title": "Welcome to R for Public Health (RPH)",
    "section": "Preamble: Setting-up your workspace",
    "text": "Preamble: Setting-up your workspace\n\nCreate a folder on your computer (preferably somewhere like C:/RPH/)\nDownload and save the course folders from the Github website: module5, module6, module7, module8, module9, module10\nInside each of these, you should see the following:\n\n\ndata/\nscripts/\noutput/\n\n\nVerify your setup looks similar to the screenshot below:\n\n\nSCREENSHOT OF WORKSPACE\n\nGreat! Now you should be ready to proceed with the next step of the course."
  },
  {
    "objectID": "index.html#installing-required-packages",
    "href": "index.html#installing-required-packages",
    "title": "Welcome to R for Public Health (RPH)",
    "section": "Installing required packages",
    "text": "Installing required packages\nYou may recall that base R only includes a minimal set of packages. For this course, we want to extend our capabilities, which will therefore require that we install some additional packages so that you can experience the wild and wonderful world of coding for data science that R has to offer.\nAt it’s simplest, the syntax for installing a new package to your computer looks something like this:\n\ninstall.packages(“name of package goes here”)\n\nSo if we wanted to, we could run this same line of code for every package that we want to install. Then, each time we open R, we’d have to invoke each of these packages that we plan on using by including this next line of code at the top of our scripts for each package that we want to load:\n\nlibrary(name of package)\n\nI don’t know about you, but to me, this feels a little tedious. Surely as we become pirate-wizards of the R universe, we can think of something a little more streamlined to help us install and load the packages we need for our exercises? Fret-not! The friendly and helpful R community has already thought of something to make this process as painless as possible, and put together a “package-manager” for us to help make our lives that much easier.\nThis package-manager, named ‘pacman’ (get it?), includes the function p_load() which checks to see if the package you want is installed, and either finds/installs/loads it for you if you haven’t installed it previously, or just loads it into your session if you have already installed it. Clever, right?\nWith this in mind, all we need to do is first install the pacman package using the old boring way, then let the p_load function take care of the rest for us!\nIn your R script, type out and execute the following code:\n\n#install.packages(\"pacman\")\nlibrary(pacman)\n\np_load(tidyverse)"
  },
  {
    "objectID": "module01.html",
    "href": "module01.html",
    "title": "Module 1",
    "section": "",
    "text": "Ahoy!\nWelcome to the first module of ArrrrrrPH! These modules are designed to provide foundational and experiential learning components of the TDU’s R for Public Health course. By working through the module, and following along with the reasoning provided, we hope that you’ll come away not only with a bit of coding muscle-memory, but also a stronger grasp of the reasoning behind why we make certain choices when it comes to working with data and coding.\nEverything that you need to complete the case study for the course should be included in these modules, but they do assume a beginner-to-intermediate working competency in R. If you have any issues getting the code to work - do not hesitate to reach out to one of your course facilitators for help.\n\n\nBy the end of Module 1, you will be able to\n\nBuild tidyverse workflows using the %&gt;% operator\nDiscuss best-practices for tidy (clean) datasets\nApply tidyverse functions to a complex dataset\n\nNow that you’ve dipped your toes into the seas of R coding, the ship’s steward has sent you the passenger manifest to work on next. As a savvy epidemiologist, however, you know that you’ll need to review and clean the data before setting sail on any analyses.\nFor this module, you’ll be required to identify parts of the manifest that need correction before using it for any coding analyses, and fix these issues using tools available to us as part of the Tidyverse collection of data-manipulation packages."
  },
  {
    "objectID": "module01.html#module-1-learning-objectives",
    "href": "module01.html#module-1-learning-objectives",
    "title": "Module 1",
    "section": "",
    "text": "Ahoy!\nWelcome to the first module of ArrrrrrPH! These modules are designed to provide foundational and experiential learning components of the TDU’s R for Public Health course. By working through the module, and following along with the reasoning provided, we hope that you’ll come away not only with a bit of coding muscle-memory, but also a stronger grasp of the reasoning behind why we make certain choices when it comes to working with data and coding.\nEverything that you need to complete the case study for the course should be included in these modules, but they do assume a beginner-to-intermediate working competency in R. If you have any issues getting the code to work - do not hesitate to reach out to one of your course facilitators for help.\n\n\nBy the end of Module 1, you will be able to\n\nBuild tidyverse workflows using the %&gt;% operator\nDiscuss best-practices for tidy (clean) datasets\nApply tidyverse functions to a complex dataset\n\nNow that you’ve dipped your toes into the seas of R coding, the ship’s steward has sent you the passenger manifest to work on next. As a savvy epidemiologist, however, you know that you’ll need to review and clean the data before setting sail on any analyses.\nFor this module, you’ll be required to identify parts of the manifest that need correction before using it for any coding analyses, and fix these issues using tools available to us as part of the Tidyverse collection of data-manipulation packages."
  },
  {
    "objectID": "module01.html#loading-our-first-dataset",
    "href": "module01.html#loading-our-first-dataset",
    "title": "Module 1",
    "section": "Loading our first dataset",
    "text": "Loading our first dataset\nLet’s try loading our first dataset.\nFor this, we’ll be using a function from the Tidyverse package. In order to do this, we’ll need to make sure that we’ve first loaded the Tidyverse into our working session.\nType the following into your R script.\n\np_load(tidyverse)\n\nGreat - now we have all of the different functions from Tidyverse available to use! For this course, we’ll only be using a very small number of the total available functions, but if you want to check out all that the Tidyverse has to offer, you can review the included packages here.\nLet’s take a look inside the folders for Module 1 - there should be three:\n\ndata/\nscripts/\noutput/\n\nInside the data/ folder you’ll find the dataset for module 1, which is saved as an excel workbook. We’ll want to convert this to an easier format to deal with later, but first let’s try loading the file into R and having a quick look at what we’re working with here!\nIn order to read the excel file directly into your computers memory without any format changes, we’ll use the readxl package, which, lucky for us, works great with tidyverse. However, the package is not included in tidyverse, so we’ll need to install and load it into memory separately.\nTry installing and loading readxl, then using the function read_excel() to load the file “ship_manifest.xlsx”\n\nreadxl::read_excel(\"participant_data/module1/ship_manifest.xlsx\")\n## # A tibble: 604 × 16\n##    Definitely not pirate…¹ ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10\n##    &lt;chr&gt;                   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n##  1 Ship:                   \"S. … &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n##  2 Captain:                \"Cpt… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n##  3 Chief Steward:          \"Peg… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n##  4 Ship Capacity:          \"814\" &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n##  5 Cruise Dates:           \"10t… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n##  6 Cruise Route:           \"Hal… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n##  7 &lt;NA&gt;                     &lt;NA&gt; &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n##  8 &lt;NA&gt;                     &lt;NA&gt; &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n##  9 Passenger Information    &lt;NA&gt; &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  Pass… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n## 10 First                   \"Las… DOB   Age   Gend… Memb… Addr… City  Prov… Coun…\n## # ℹ 594 more rows\n## # ℹ abbreviated name: ¹​`Definitely not pirates cruise ship company ™`\n## # ℹ 6 more variables: ...11 &lt;chr&gt;, ...12 &lt;chr&gt;, ...13 &lt;chr&gt;, ...14 &lt;chr&gt;,\n## #   ...15 &lt;chr&gt;, ...16 &lt;chr&gt;\n\nOkay, something appears to not be working as expected here. Let’s open the file in Excel and see what’s going on…\n\n\n\n\n\n\nWarning\n\n\n\n\n\n\nThe header section of the passenger manifest\n\n\n\n\nYikes!\nWhen will these fictional-nautical-based-tourism-that-definitely-aren’t-pirates-companies ever learn to make their data collection forms friendly with machine-readable tools?\nOkay but all kidding aside - get used to it! Navigating strange formatting issues is a highly-useful skill that will come in handy many times in your public health career!"
  },
  {
    "objectID": "module01.html#tidy-data-and-r",
    "href": "module01.html#tidy-data-and-r",
    "title": "Module 1",
    "section": "Tidy data and R",
    "text": "Tidy data and R\nWhen we interpret tables in R, the software is expecting consistent columns, each containing a unique variable, with the top row of all the columns containing a name for each variable. If we look a little more closely, we can actually see that this is the case for the useful data in the form, however, we first need to tell R to remove, or skip, the rows of the form that do not contain useful information.\nFortunately, this is pretty easy to do with our read_excel() function. Review the function help using the following line of code.\n\nhelp(read_excel)\n\nThis should pop up the help file in the bottom right pane in RStudio, where you’ll see the following under the function usage:\n\nread_excel(\npath,\nsheet = NULL,\nrange = NULL,\ncol_names = TRUE,\ncol_types = NULL,\nna = ““,\ntrim_ws = TRUE,\nskip = 0,\nn_max = Inf,\nguess_max = min(1000, n_max),\nprogress = readxl_progress(),\n.name_repair =”unique”\n)\n\nThe argument that we’re interested in is skip = 0. If we include this argument in our read_excel() function, then R will automatically skip the number of rows indicated. Let’s try running the code again, but this time, skipping over the first 10 rows of the worksheet.\nWe’ll also save the file to an object called ‘manifest’ so we can easily modify and use it later on.\n\n\nmanifest &lt;- readxl::read_excel(\"participant_data/module1/ship_manifest.xlsx\", \n                               skip = 10)"
  },
  {
    "objectID": "module01.html#identifying-data-cleaning-needs",
    "href": "module01.html#identifying-data-cleaning-needs",
    "title": "Module 1",
    "section": "Identifying data cleaning needs",
    "text": "Identifying data cleaning needs\nLet’s take a moment now to review the manifest object and learn a little about it. There are several functions that can help you become familiar with data objects. Because we’re mainly focused here on using as many Tidyverse functions as possible, let’s check out the function glimpse(). This function operates very similarly to the base R structure function str(), however, provides the output in a more neatly organized way. Try it out on the manifest object you imported earlier.\n\nglimpse(manifest)\n## Rows: 594\n## Columns: 16\n## $ First...1           &lt;chr&gt; \"Nicole\", \"Nicole\", \"Scott\", \"Julie\", \"Kaitlyn\", \"…\n## $ Last...2            &lt;chr&gt; \"Miller\", \"Ramirez\", \"Ramirez\", \"Spencer\", \"Jones\"…\n## $ DOB                 &lt;chr&gt; \"21445\", \"27047\", \"28507\", \"36314\", \"35219\", \"2358…\n## $ Age                 &lt;dbl&gt; 67, 51, 47, 26, 29, 61, 62, 27, 28, 30, 54, 27, 39…\n## $ Gender              &lt;chr&gt; \"Female\", \"Female\", \"Male\", \"Female\", \"Female\", \"M…\n## $ `Member Status`     &lt;chr&gt; \"Silver\", \"Platinum\", \"Platinum\", \"Silver\", \"Silve…\n## $ Address             &lt;chr&gt; \"8125 Tony Stravenue Boulevard, Lethbridge, Albert…\n## $ City                &lt;chr&gt; \"Lethbridge\", \"Red Deer\", \"Red Deer\", \"Red Deer\", …\n## $ Province            &lt;chr&gt; \"AB\", \"AB\", \"AB\", \"AB\", \"AB\", \"British Columbia\", …\n## $ Country             &lt;chr&gt; \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Canada\", …\n## $ First...11          &lt;chr&gt; \"Lisa\", \"Jeffrey\", \"Jeffrey\", \"Bradley\", \"Bradley\"…\n## $ Last...12           &lt;chr&gt; \"Jackson\", \"Meyer\", \"Meyer\", \"Robertson\", \"Roberts…\n## $ Relationship        &lt;chr&gt; \"Relative\", \"Relative\", \"Relative\", \"Other\", \"Othe…\n## $ `Phone number`      &lt;chr&gt; \"(483) 503-0564\", \"(356) 159-5148\", \"(356) 159-514…\n## $ `Boarding Date`     &lt;chr&gt; \"Feb 9th\", \"Feb 9th\", \"Feb 9th\", \"Feb 9th\", \"Feb 9…\n## $ `Boarding Location` &lt;chr&gt; \"Halifax, NS\", \"Halifax, NS\", \"Halifax, NS\", \"Hali…\n\nTake a few minutes to further explore the data however you see fit, and jot down any characteristics about the dataset that you think might pose a problem later on. When you’re done that, review the code provided below and note how your data-cleaning process compared to ours.\nA few tips to keep in mind when looking for potential data issues:\n\nAre variables named consistently and without spaces or special characters?\nAre the data contained within each variable consistent? I.e., only one data type per variable?\nAre there missing values within any of your variables? What about sentinel values like those in the following table? How will you plan to treat these?\n\nTable of sentinel values\n\n\n\n\n\n\nValue or symbol\nDescription\n\n\n\n\n.\nPeriod. Often used to denote purposely missing values in programs like Stata.\n\n\n-\nDash. Can denote missing value, negative, empty cell, or errors.\n\n\n999\nThree nines (999). This code is often used to represent ‘missing’ or ‘unknown’.\n\n\nN/A\nNot applicable. This is sometimes written purposively, and other times is an automatic replacement for blank cells.\n\n\nMissing\nThe word ‘missing.’ This is often input manually by someone who wants signify that the data were not collected, and that an empty cell is not the result of a data entry error.\n\n\n(blank)\nBlank cell. Impossible to know whether a cell was left intentionally blank, or whether it is the result of data entry errors.\n\n\n\nHow are dates formatted?\nHow do you want place names to be formatted? E.g., should provinces be spelled out in full, or is it easier to replace these with abbreviated versions?\nAre there extraneous variables in the data? If yes, what do you propose doing with these?\n\n\nWhen you’re ready - let’s move on and see how your findings compared to ours! Below is a list of issues that we found with the passenger manifest table.\n\n\nClick to show the list\n\n\nOnce the header information was removed to make the file human-readable, we lost the information about whether variables were capturing passenger information, or emergency contact information. As a result, we now have duplicated variable names! This will not do! We’ll need to remove or change the variables names to ensure that each one is unique and informative. While we’re at it - we should make sure that none of our variables contain special characters or spaces in them too.\nIn the DOB variable, there appears to be multiple different formats. We’ll need to fix this as this is a very important variable if we want to know the passenger’s age.\nSpeaking of age.. it looks like someone was trying to use an Excel formula to calculate it - but pretty quickly ran into a snag due to some incorrect formatting in the DOB column, resulting in a lot of “#N/A” inputs. We’ll want to replace the current Age variable with a corrected version.\nProvince of residence appears to have quite a number of different formats going on, between fully-spelled-out versions of province names and abbreviated versions. We’ll need to capture the unique set of these, and ensure that we take a consistent approach.\nEmergency contact information appears to have undergone some input issues as well. Even though the variables are supposed to include first and last names, it appears that titles and professional designations somehow made it in, and is causing some issues. Also - there are quite a few missing entries, so we’ll need to make some decisions on what to do with these data.\nBoarding Date for some reason has the date written out in a non-date format. We should probably fix this as well."
  },
  {
    "objectID": "module01.html#data-cleaning-steps",
    "href": "module01.html#data-cleaning-steps",
    "title": "Module 1",
    "section": "Data cleaning steps",
    "text": "Data cleaning steps\nNow that we have our list, let’s get started on cleaning the dataset so that it can be useful for future cross-referencing whenever we need to look up something about our passengers.\n\nStep 1: Rename variables\n\n\n# First, let's get a list of all the variables currently included in the manifest dataset\n\nvars &lt;- names(manifest)\n\nprint(vars)\n##  [1] \"First...1\"         \"Last...2\"          \"DOB\"              \n##  [4] \"Age\"               \"Gender\"            \"Member Status\"    \n##  [7] \"Address\"           \"City\"              \"Province\"         \n## [10] \"Country\"           \"First...11\"        \"Last...12\"        \n## [13] \"Relationship\"      \"Phone number\"      \"Boarding Date\"    \n## [16] \"Boarding Location\"\n\nThere appears to be two problems happening here:\n\nFirst…1 and Last…2 versus First…11 and Last…12 - we’ll need to fix these so that they make more sense and are easier to work with.\nSeveral variables include spaces in their naming, so we’ll fix that too.\n\n\n#Create a new variable that includes the corrected names of variables for the passenger manifest:\n\nfixed_vars &lt;- c(\"pass.fname\", \n                \"pass.lname\", \n                \"pass.dob\",\n                \"pass.age\",\n                \"pass.gender\", \n                \"pass.status\",\n                \"home.address\",\n                \"home.city\",\n                \"home.prov\", \n                \"home.country\",\n                \"emerg.contact.fname\",\n                \"emerg.contact.lname\",\n                \"emerg.contact.relationship\",\n                \"emerg.contact.phone\",\n                \"board.date\",\n                \"board.location\")\n\n# Replace the variable names in the dataset with the corrected versions: \nnames(manifest) &lt;- fixed_vars\n\n# Print the names and double check that it worked! \nnames(manifest)\n##  [1] \"pass.fname\"                 \"pass.lname\"                \n##  [3] \"pass.dob\"                   \"pass.age\"                  \n##  [5] \"pass.gender\"                \"pass.status\"               \n##  [7] \"home.address\"               \"home.city\"                 \n##  [9] \"home.prov\"                  \"home.country\"              \n## [11] \"emerg.contact.fname\"        \"emerg.contact.lname\"       \n## [13] \"emerg.contact.relationship\" \"emerg.contact.phone\"       \n## [15] \"board.date\"                 \"board.location\"\n\nExcellent, we can cross the first item off of our list: fixing variable names. Next, let’s look at the date of birth variable.\n\n\nStep 2: Fix date of birth\n\n\n#Let's have a look at the data in the dob variable: \n\nglimpse(manifest %&gt;% select(pass.dob))\n## Rows: 594\n## Columns: 1\n## $ pass.dob &lt;chr&gt; \"21445\", \"27047\", \"28507\", \"36314\", \"35219\", \"23589\", \"23224\"…\n\nWait a second.. oh no. Excel again..\nSo it turns out, that by reading these data in directly from Excel, we have retained some Excel-scurvy! Dates in excel are formatted in a very unique way: it simply counts the number of days passed starting with “1” on January 1, 1900.\nWe’ll need to use a few extra tricks it seems to fix this issue. But first, lets strategize a couple different ways to do this.\n\nThe easiest, is probably to reopen the file in Excel - fix the few dates that aren’t formatted the same as the majority, and then re-write all the dates in a non-date format in Excel. This is an R course, though, so we’re not going to do that!\nAs alluded to in the above suggestion, we should first focus on making all the data in the variable consistent, then do some operation on all them at once. We can do this easily enough in R, and using a scripting language helps us keep track of everything we did, compared to Excel where we can get distracted and forget to record our steps. Win win.\n\n\n\n# Let's start by printing the entire DOB variable and checking which entries need fixing: \n\nbirthdates &lt;- manifest$pass.dob\nprint(birthdates)\n##   [1] \"21445\"          \"27047\"          \"28507\"          \"36314\"         \n##   [5] \"35219\"          \"23589\"          \"23224\"          \"35962\"         \n##   [9] \"35506\"          \"34776\"          \"26125\"          \"36119\"         \n##  [13] \"31647\"          \"August 21 1992\" \"17882\"          \"21782\"         \n##  [17] \"21052\"          \"34099\"          \"35194\"          \"23545\"         \n##  [21] \"22815\"          \"17244\"          \"36900\"          \"30627\"         \n##  [25] \"30262\"          \"18054\"          \"20244\"          \"33628\"         \n##  [29] \"33994\"          \"29601\"          \"31791\"          \"33258\"         \n##  [33] \"33623\"          \"28136\"          \"17175\"          \"30936\"         \n##  [37] \"32396\"          \"31966\"          \"32225\"          \"29021\"         \n##  [41] \"27226\"          \"23761\"          \"23031\"          \"35988\"         \n##  [45] \"32639\"          \"30814\"          \"31287\"          \"33113\"         \n##  [49] \"28474\"          \"26284\"          \"35149\"          \"35863\"         \n##  [53] \"26843\"          \"26478\"          \"35980\"          \"36710\"         \n##  [57] \"16753\"          \"14563\"          \"31415\"          \"33605\"         \n##  [61] \"32037\"          \"30942\"          \"18969\"          \"19670\"         \n##  [65] \"17763\"          \"33145\"          \"30956\"          \"30811\"         \n##  [69] \"30081\"          \"25630\"          \"18806\"          \"20266\"         \n##  [73] \"32151\"          \"33976\"          \"16520\"          \"31902\"         \n##  [77] \"31598\"          \"30492\"          \"30127\"          \"23592\"         \n##  [81] \"31542\"          \"32637\"          \"25419\"          \"26879\"         \n##  [85] \"23167\"          \"21707\"          \"13065\"          \"28288\"         \n##  [89] \"27193\"          \"20233\"          \"22062\"          \"32375\"         \n##  [93] \"32534\"          \"35077\"          \"22915\"          \"23178\"         \n##  [97] \"1982.08.30\"     \"29089\"          \"19278\"          \"35450\"         \n## [101] \"36545\"          \"39667\"          \"27979\"          \"29697\"         \n## [105] \"31668\"          \"33128\"          \"33932\"          \"31742\"         \n## [109] \"23227\"          \"19534\"          \"17344\"          \"26978\"         \n## [113] \"28438\"          \"24090\"          \"21900\"          \"23393\"         \n## [117] \"25822\"          \"23964\"          \"22740\"          \"33431\"         \n## [121] \"34473\"          \"30508\"          \"30892\"          \"28378\"         \n## [125] \"28626\"          \"36319\"          \"1993\\\\03\\\\09\"   \"26278\"         \n## [129] \"27435\"          \"30606\"          \"29876\"          \"32136\"         \n## [133] \"28948\"          \"29678\"          \"28518\"          \"30708\"         \n## [137] \"34770\"          \"36230\"          \"29411\"          \"32282\"         \n## [141] \"25421\"          \"26700\"          \"22657\"          \"21562\"         \n## [145] \"31551\"          \"28994\"          \"21019\"          \"20572\"         \n## [149] \"26042\"          \"33020\"          \"21720\"          \"22815\"         \n## [153] \"24514\"          \"25456\"          \"1959-13-01\"     \"28012\"         \n## [157] \"26792\"          \"20473\"          \"21203\"          \"17327\"         \n## [161] \"19187\"          \"19826\"          \"20202\"          \"36392\"         \n## [165] \"29588\"          \"30599\"          \"30055\"          \"24150\"         \n## [169] \"23055\"          \"29145\"          \"17704\"          \"33541\"         \n## [173] \"32081\"          \"34283\"          \"31620\"          \"30031\"         \n## [177] \"28897\"          \"26707\"          \"26053\"          \"31623\"         \n## [181] \"30923\"          \"23930\"          \"22713\"          \"25842\"         \n## [185] \"26207\"          \"26010\"          \"28169\"          \"35542\"         \n## [189] \"34021\"          \"28427\"          \"27130\"          \"33230\"         \n## [193] \"29733\"          \"29978\"          \"31288\"          \"36799\"         \n## [197] \"16590\"          \"16950\"          \"34119\"          \"34200\"         \n## [201] \"21325\"          \"20230\"          \"18033\"          \"19035\"         \n## [205] \"29840\"          \"31069\"          \"31026\"          \"30021\"         \n## [209] \"30176\"          \"31985\"          \"21839\"          \"20059\"         \n## [213] \"35343\"          \"35759\"          \"29414\"          \"22334\"         \n## [217] \"24432\"          \"22457\"          \"22057\"          \"33930\"         \n## [221] \"35987\"          \"23519\"          \"31424\"          \"27418\"         \n## [225] \"26973\"          \"39263\"          \"30145\"          \"42605\"         \n## [229] \"32205\"          \"31037\"          \"39960\"          \"26085\"         \n## [233] \"27129\"          \"41364\"          \"38990\"          \"31481\"         \n## [237] \"31204\"          \"26540\"          \"26297\"          \"27205\"         \n## [241] \"18378\"          \"31911\"          \"32104\"          \"21965\"         \n## [245] \"22289\"          \"30946\"          \"30723\"          \"41204\"         \n## [249] \"13985\"          \"28136\"          \"25946\"          \"27834\"         \n## [253] \"17879\"          \"31449\"          \"30650\"          \"31843\"         \n## [257] \"30200\"          \"41869\"          \"25017\"          \"26924\"         \n## [261] \"20042\"          \"18966\"          \"31093\"          \"23116\"         \n## [265] \"30373\"          \"29722\"          \"20496\"          \"20603\"         \n## [269] \"36954\"          \"29372\"          \"29007\"          \"20500\"         \n## [273] \"23631\"          \"23430\"          \"23192\"          \"22097\"         \n## [277] \"35339\"          \"20936\"          \"33454\"          \"35279\"         \n## [281] \"41691\"          \"31737\"          \"31372\"          \"38281\"         \n## [285] \"25848\"          \"25483\"          \"34384\"          \"35479\"         \n## [289] \"35112\"          \"37302\"          \"33492\"          \"42365\"         \n## [293] \"42334\"          \"18686\"          \"32016\"          \"33476\"         \n## [297] \"30167\"          \"29072\"          \"23903\"          \"18472\"         \n## [301] \"19932\"          \"35442\"          \"15166\"          \"32337\"         \n## [305] \"33291\"          \"31861\"          \"33686\"          \"29651\"         \n## [309] \"28556\"          \"34419\"          \"24315\"          \"23950\"         \n## [313] \"32727\"          \"33092\"          \"35791\"          \"33601\"         \n## [317] \"29865\"          \"31690\"          \"17091\"          \"17821\"         \n## [321] \"30697\"          \"31427\"          \"19003\"          \"17908\"         \n## [325] \"17943\"          \"19038\"          \"23510\"          \"24605\"         \n## [329] \"23310\"          \"22366\"          \"26667\"          \"27032\"         \n## [333] \"31337\"          \"32432\"          \"30875\"          \"28561\"         \n## [337] \"32966\"          \"33396\"          \"30045\"          \"33783\"         \n## [341] \"33053\"          \"27808\"          \"25618\"          \"17459\"         \n## [345] \"26154\"          \"24693\"          \"21673\"          \"23863\"         \n## [349] \"25027\"          \"25545\"          \"25249\"          \"24427\"         \n## [353] \"32845\"          \"34670\"          \"28681\"          \"21371\"         \n## [357] \"27241\"          \"27606\"          \"25260\"          \"27085\"         \n## [361] \"29667\"          \"29419\"          \"30514\"          \"35887\"         \n## [365] \"36617\"          \"13342\"          \"32994\"          \"31070\"         \n## [369] \"20373\"          \"17579\"          \"35827\"          \"36505\"         \n## [373] \"17012\"          \"16283\"          \"29027\"          \"29454\"         \n## [377] \"27286\"          \"28016\"          \"33529\"          \"32069\"         \n## [381] \"28397\"          \"29795\"          \"40128\"          \"18734\"         \n## [385] \"19088\"          \"20303\"          \"22235\"          \"23330\"         \n## [389] \"24299\"          \"22474\"          \"19791\"          \"32112\"         \n## [393] \"33207\"          \"29246\"          \"27786\"          \"28295\"         \n## [397] \"27565\"          \"22939\"          \"23304\"          \"30427\"         \n## [401] \"28602\"          \"29613\"          \"30708\"          \"22637\"         \n## [405] \"23367\"          \"31375\"          \"33049\"          \"18664\"         \n## [409] \"24206\"          \"21278\"          \"21643\"          \"29419\"         \n## [413] \"27594\"          \"33970\"          \"28501\"          \"23385\"         \n## [417] \"37121\"          \"35661\"          \"18787\"          \"18422\"         \n## [421] \"33249\"          \"33709\"          \"34408\"          \"34010\"         \n## [425] \"24177\"          \"23813\"          \"41820\"          \"26822\"         \n## [429] \"26457\"          \"25844\"          \"24871\"          \"12529\"         \n## [433] \"26216\"          \"24026\"          \"26605\"          \"29946\"         \n## [437] \"29216\"          \"30170\"          \"28740\"          \"29257\"         \n## [441] \"23401\"          \"22849\"          \"22908\"          \"25098\"         \n## [445] \"25129\"          \"27323\"          \"20054\"          \"33182\"         \n## [449] \"32213\"          \"27909\"          \"29734\"          \"16472\"         \n## [453] \"28628\"          \"29352\"          \"27162\"          \"32544\"         \n## [457] \"31084\"          \"27762\"          \"25934\"          \"30175\"         \n## [461] \"30813\"          \"26102\"          \"23912\"          \"15100\"         \n## [465] \"33988\"          \"33853\"          \"28710\"          \"26550\"         \n## [469] \"30398\"          \"32308\"          \"36487\"          \"36852\"         \n## [473] \"30950\"          \"30771\"          \"24272\"          \"22883\"         \n## [477] \"15960\"          \"28034\"          \"28415\"          \"30691\"         \n## [481] \"29901\"          \"18532\"          \"19922\"          \"26371\"         \n## [485] \"16445\"          \"14255\"          \"24067\"          \"22727\"         \n## [489] \"32163\"          \"30885\"          \"18894\"          \"28178\"         \n## [493] \"29613\"          \"30725\"          \"31780\"          \"26180\"         \n## [497] \"28170\"          \"33523\"          \"33602\"          \"18908\"         \n## [501] \"20368\"          \"29139\"          \"27314\"          \"28794\"         \n## [505] \"26969\"          \"31058\"          \"30725\"          \"31145\"         \n## [509] \"31690\"          \"30018\"          \"30508\"          \"19205\"         \n## [513] \"27836\"          \"29480\"          \"16204\"          \"30682\"         \n## [517] \"31945\"          \"26765\"          \"30241\"          \"31704\"         \n## [521] \"22755\"          \"24751\"          \"23322\"          \"25455\"         \n## [525] \"26734\"          \"26293\"          \"27722\"          \"28568\"         \n## [529] \"35367\"          \"34328\"          \"28938\"          \"28290\"         \n## [533] \"28637\"          \"29753\"          \"17688\"          \"16838\"         \n## [537] \"31480\"          \"22323\"          \"23273\"          \"22659\"         \n## [541] \"24624\"          \"38576\"          \"24743\"          \"25082\"         \n## [545] \"26239\"          \"24370\"          \"40007\"          \"27966\"         \n## [549] \"27557\"          \"27479\"          \"28471\"          \"24233\"         \n## [553] \"25826\"          \"29297\"          \"28047\"          \"26560\"         \n## [557] \"29173\"          \"28991\"          \"21039\"          \"19967\"         \n## [561] \"31104\"          \"32600\"          \"28545\"          \"29118\"         \n## [565] \"13246\"          \"31359\"          \"29862\"          \"1968-July-18th\"\n## [569] \"19127\"          \"18770\"          \"22661\"          \"23178\"         \n## [573] \"23552\"          \"25965\"          \"26291\"          \"21520\"         \n## [577] \"36070\"          \"35382\"          \"26373\"          \"25991\"         \n## [581] \"26374\"          \"32308\"          \"30848\"          \"28901\"         \n## [585] \"26943\"          \"32382\"          \"32637\"          \"41131\"         \n## [589] \"29576\"          \"28390\"          \"40138\"          \"31410\"         \n## [593] \"25090\"          \"16308\"\n\nIf we look through the data, there’s actually only 5 entries with issues:\n\nEntry 14 - Aug 21, 1992\nEntry 97 - Aug 30, 1982\nEntry 127 - Mar 9, 1993\nEntry 155 - Jan 13, 1959 (let’s assume the order of month and day were mixed)\nEntry 568 - Jul 18, 1968\n\nThese are all easy to fix if we stick with indices that we learned about in R-basics.. but we’ll need to convert these dates into Excel format first, then revert everything into a more sensical format once everything is numeric.\nWe’ll want to convert the intended date to a class that we can deal with numerically, then extract the number of days between that date and the beginning of 1900-01-01 to get the date as an excel format. Lubridate makes this pretty easy for us with the ymd() function!\n\n# library(lubridate)\n\nbirthdates[14] &lt;- ymd(\"1992-08-21\") - ymd(\"1899-12-30\")\nbirthdates[97] &lt;- ymd(\"1982-08-30\") - ymd(\"1899-12-30\")\nbirthdates[127] &lt;- ymd(\"1993-03-09\") - ymd(\"1899-12-30\")\nbirthdates[155] &lt;- ymd(\"1959-01-13\") - ymd(\"1899-12-30\")\nbirthdates[568] &lt;- ymd(\"1968-07-18\") - ymd(\"1899-12-30\")\n\nprint(birthdates) # check to make sure everything looks OK\n##   [1] \"21445\" \"27047\" \"28507\" \"36314\" \"35219\" \"23589\" \"23224\" \"35962\" \"35506\"\n##  [10] \"34776\" \"26125\" \"36119\" \"31647\" \"33837\" \"17882\" \"21782\" \"21052\" \"34099\"\n##  [19] \"35194\" \"23545\" \"22815\" \"17244\" \"36900\" \"30627\" \"30262\" \"18054\" \"20244\"\n##  [28] \"33628\" \"33994\" \"29601\" \"31791\" \"33258\" \"33623\" \"28136\" \"17175\" \"30936\"\n##  [37] \"32396\" \"31966\" \"32225\" \"29021\" \"27226\" \"23761\" \"23031\" \"35988\" \"32639\"\n##  [46] \"30814\" \"31287\" \"33113\" \"28474\" \"26284\" \"35149\" \"35863\" \"26843\" \"26478\"\n##  [55] \"35980\" \"36710\" \"16753\" \"14563\" \"31415\" \"33605\" \"32037\" \"30942\" \"18969\"\n##  [64] \"19670\" \"17763\" \"33145\" \"30956\" \"30811\" \"30081\" \"25630\" \"18806\" \"20266\"\n##  [73] \"32151\" \"33976\" \"16520\" \"31902\" \"31598\" \"30492\" \"30127\" \"23592\" \"31542\"\n##  [82] \"32637\" \"25419\" \"26879\" \"23167\" \"21707\" \"13065\" \"28288\" \"27193\" \"20233\"\n##  [91] \"22062\" \"32375\" \"32534\" \"35077\" \"22915\" \"23178\" \"30193\" \"29089\" \"19278\"\n## [100] \"35450\" \"36545\" \"39667\" \"27979\" \"29697\" \"31668\" \"33128\" \"33932\" \"31742\"\n## [109] \"23227\" \"19534\" \"17344\" \"26978\" \"28438\" \"24090\" \"21900\" \"23393\" \"25822\"\n## [118] \"23964\" \"22740\" \"33431\" \"34473\" \"30508\" \"30892\" \"28378\" \"28626\" \"36319\"\n## [127] \"34037\" \"26278\" \"27435\" \"30606\" \"29876\" \"32136\" \"28948\" \"29678\" \"28518\"\n## [136] \"30708\" \"34770\" \"36230\" \"29411\" \"32282\" \"25421\" \"26700\" \"22657\" \"21562\"\n## [145] \"31551\" \"28994\" \"21019\" \"20572\" \"26042\" \"33020\" \"21720\" \"22815\" \"24514\"\n## [154] \"25456\" \"21563\" \"28012\" \"26792\" \"20473\" \"21203\" \"17327\" \"19187\" \"19826\"\n## [163] \"20202\" \"36392\" \"29588\" \"30599\" \"30055\" \"24150\" \"23055\" \"29145\" \"17704\"\n## [172] \"33541\" \"32081\" \"34283\" \"31620\" \"30031\" \"28897\" \"26707\" \"26053\" \"31623\"\n## [181] \"30923\" \"23930\" \"22713\" \"25842\" \"26207\" \"26010\" \"28169\" \"35542\" \"34021\"\n## [190] \"28427\" \"27130\" \"33230\" \"29733\" \"29978\" \"31288\" \"36799\" \"16590\" \"16950\"\n## [199] \"34119\" \"34200\" \"21325\" \"20230\" \"18033\" \"19035\" \"29840\" \"31069\" \"31026\"\n## [208] \"30021\" \"30176\" \"31985\" \"21839\" \"20059\" \"35343\" \"35759\" \"29414\" \"22334\"\n## [217] \"24432\" \"22457\" \"22057\" \"33930\" \"35987\" \"23519\" \"31424\" \"27418\" \"26973\"\n## [226] \"39263\" \"30145\" \"42605\" \"32205\" \"31037\" \"39960\" \"26085\" \"27129\" \"41364\"\n## [235] \"38990\" \"31481\" \"31204\" \"26540\" \"26297\" \"27205\" \"18378\" \"31911\" \"32104\"\n## [244] \"21965\" \"22289\" \"30946\" \"30723\" \"41204\" \"13985\" \"28136\" \"25946\" \"27834\"\n## [253] \"17879\" \"31449\" \"30650\" \"31843\" \"30200\" \"41869\" \"25017\" \"26924\" \"20042\"\n## [262] \"18966\" \"31093\" \"23116\" \"30373\" \"29722\" \"20496\" \"20603\" \"36954\" \"29372\"\n## [271] \"29007\" \"20500\" \"23631\" \"23430\" \"23192\" \"22097\" \"35339\" \"20936\" \"33454\"\n## [280] \"35279\" \"41691\" \"31737\" \"31372\" \"38281\" \"25848\" \"25483\" \"34384\" \"35479\"\n## [289] \"35112\" \"37302\" \"33492\" \"42365\" \"42334\" \"18686\" \"32016\" \"33476\" \"30167\"\n## [298] \"29072\" \"23903\" \"18472\" \"19932\" \"35442\" \"15166\" \"32337\" \"33291\" \"31861\"\n## [307] \"33686\" \"29651\" \"28556\" \"34419\" \"24315\" \"23950\" \"32727\" \"33092\" \"35791\"\n## [316] \"33601\" \"29865\" \"31690\" \"17091\" \"17821\" \"30697\" \"31427\" \"19003\" \"17908\"\n## [325] \"17943\" \"19038\" \"23510\" \"24605\" \"23310\" \"22366\" \"26667\" \"27032\" \"31337\"\n## [334] \"32432\" \"30875\" \"28561\" \"32966\" \"33396\" \"30045\" \"33783\" \"33053\" \"27808\"\n## [343] \"25618\" \"17459\" \"26154\" \"24693\" \"21673\" \"23863\" \"25027\" \"25545\" \"25249\"\n## [352] \"24427\" \"32845\" \"34670\" \"28681\" \"21371\" \"27241\" \"27606\" \"25260\" \"27085\"\n## [361] \"29667\" \"29419\" \"30514\" \"35887\" \"36617\" \"13342\" \"32994\" \"31070\" \"20373\"\n## [370] \"17579\" \"35827\" \"36505\" \"17012\" \"16283\" \"29027\" \"29454\" \"27286\" \"28016\"\n## [379] \"33529\" \"32069\" \"28397\" \"29795\" \"40128\" \"18734\" \"19088\" \"20303\" \"22235\"\n## [388] \"23330\" \"24299\" \"22474\" \"19791\" \"32112\" \"33207\" \"29246\" \"27786\" \"28295\"\n## [397] \"27565\" \"22939\" \"23304\" \"30427\" \"28602\" \"29613\" \"30708\" \"22637\" \"23367\"\n## [406] \"31375\" \"33049\" \"18664\" \"24206\" \"21278\" \"21643\" \"29419\" \"27594\" \"33970\"\n## [415] \"28501\" \"23385\" \"37121\" \"35661\" \"18787\" \"18422\" \"33249\" \"33709\" \"34408\"\n## [424] \"34010\" \"24177\" \"23813\" \"41820\" \"26822\" \"26457\" \"25844\" \"24871\" \"12529\"\n## [433] \"26216\" \"24026\" \"26605\" \"29946\" \"29216\" \"30170\" \"28740\" \"29257\" \"23401\"\n## [442] \"22849\" \"22908\" \"25098\" \"25129\" \"27323\" \"20054\" \"33182\" \"32213\" \"27909\"\n## [451] \"29734\" \"16472\" \"28628\" \"29352\" \"27162\" \"32544\" \"31084\" \"27762\" \"25934\"\n## [460] \"30175\" \"30813\" \"26102\" \"23912\" \"15100\" \"33988\" \"33853\" \"28710\" \"26550\"\n## [469] \"30398\" \"32308\" \"36487\" \"36852\" \"30950\" \"30771\" \"24272\" \"22883\" \"15960\"\n## [478] \"28034\" \"28415\" \"30691\" \"29901\" \"18532\" \"19922\" \"26371\" \"16445\" \"14255\"\n## [487] \"24067\" \"22727\" \"32163\" \"30885\" \"18894\" \"28178\" \"29613\" \"30725\" \"31780\"\n## [496] \"26180\" \"28170\" \"33523\" \"33602\" \"18908\" \"20368\" \"29139\" \"27314\" \"28794\"\n## [505] \"26969\" \"31058\" \"30725\" \"31145\" \"31690\" \"30018\" \"30508\" \"19205\" \"27836\"\n## [514] \"29480\" \"16204\" \"30682\" \"31945\" \"26765\" \"30241\" \"31704\" \"22755\" \"24751\"\n## [523] \"23322\" \"25455\" \"26734\" \"26293\" \"27722\" \"28568\" \"35367\" \"34328\" \"28938\"\n## [532] \"28290\" \"28637\" \"29753\" \"17688\" \"16838\" \"31480\" \"22323\" \"23273\" \"22659\"\n## [541] \"24624\" \"38576\" \"24743\" \"25082\" \"26239\" \"24370\" \"40007\" \"27966\" \"27557\"\n## [550] \"27479\" \"28471\" \"24233\" \"25826\" \"29297\" \"28047\" \"26560\" \"29173\" \"28991\"\n## [559] \"21039\" \"19967\" \"31104\" \"32600\" \"28545\" \"29118\" \"13246\" \"31359\" \"29862\"\n## [568] \"25037\" \"19127\" \"18770\" \"22661\" \"23178\" \"23552\" \"25965\" \"26291\" \"21520\"\n## [577] \"36070\" \"35382\" \"26373\" \"25991\" \"26374\" \"32308\" \"30848\" \"28901\" \"26943\"\n## [586] \"32382\" \"32637\" \"41131\" \"29576\" \"28390\" \"40138\" \"31410\" \"25090\" \"16308\"\n\nNow that we’ve created a new variable with the correct Excel formats, let’s convert it into the correct date format, and save the whole variable back to the manifest.\n\n\n# Use as_date() from lubridate, and set the Excel origin\n# We'll need to change our birthdates back to numeric first, as well. \n\nbirthdates &lt;- as_date(as.numeric(birthdates), origin= \"1899-12-30\")\nmanifest$pass.dob &lt;- birthdates\n\n# Doublecheck to make sure that the DOB column now looks good: \nglimpse(manifest)\n## Rows: 594\n## Columns: 16\n## $ pass.fname                 &lt;chr&gt; \"Nicole\", \"Nicole\", \"Scott\", \"Julie\", \"Kait…\n## $ pass.lname                 &lt;chr&gt; \"Miller\", \"Ramirez\", \"Ramirez\", \"Spencer\", …\n## $ pass.dob                   &lt;date&gt; 1958-09-17, 1974-01-18, 1978-01-17, 1999-0…\n## $ pass.age                   &lt;dbl&gt; 67, 51, 47, 26, 29, 61, 62, 27, 28, 30, 54,…\n## $ pass.gender                &lt;chr&gt; \"Female\", \"Female\", \"Male\", \"Female\", \"Fema…\n## $ pass.status                &lt;chr&gt; \"Silver\", \"Platinum\", \"Platinum\", \"Silver\",…\n## $ home.address               &lt;chr&gt; \"8125 Tony Stravenue Boulevard, Lethbridge,…\n## $ home.city                  &lt;chr&gt; \"Lethbridge\", \"Red Deer\", \"Red Deer\", \"Red …\n## $ home.prov                  &lt;chr&gt; \"AB\", \"AB\", \"AB\", \"AB\", \"AB\", \"British Colu…\n## $ home.country               &lt;chr&gt; \"Canada\", \"Canada\", \"Canada\", \"Canada\", \"Ca…\n## $ emerg.contact.fname        &lt;chr&gt; \"Lisa\", \"Jeffrey\", \"Jeffrey\", \"Bradley\", \"B…\n## $ emerg.contact.lname        &lt;chr&gt; \"Jackson\", \"Meyer\", \"Meyer\", \"Robertson\", \"…\n## $ emerg.contact.relationship &lt;chr&gt; \"Relative\", \"Relative\", \"Relative\", \"Other\"…\n## $ emerg.contact.phone        &lt;chr&gt; \"(483) 503-0564\", \"(356) 159-5148\", \"(356) …\n## $ board.date                 &lt;chr&gt; \"Feb 9th\", \"Feb 9th\", \"Feb 9th\", \"Feb 9th\",…\n## $ board.location             &lt;chr&gt; \"Halifax, NS\", \"Halifax, NS\", \"Halifax, NS\"…\n\nNow you can see that the pass.dob variable contains all dates in an actual date format. Hurrah!\n\n\nStep 3: (Re-)Create an age variable from DOB\nAfter the shenanigans involved in the last step, this should be an absolute sea-breeze. Let’s recreate the age variable in our dataset, using the passenger date of birth, and the date that the cruise set sail as the day to calculate age.\nThe way that we treat age can be a little tricky, so it’s best to break it down into smaller steps, working backwards like so:\n\nCalculate the time interval passed between the date of birth and the departure date of the S.S. Rainbow Cake\n\n\ninterval(pass.dob, ymd(“2025-02-10”))\n\n\nGet the exact length of that interval, and return the value in years\n\n\ntime_length(interval, “years”)\n\n\nRound that value down to an integer\n\n\nfloor(time_length)\n\n\nSave this as a new variable in your manifest data frame\n\n\nmutate(pass.age = …)\n\nTry coding these all into one statement on your own, then check against our code below!\n\n\nmanifest &lt;- \n  manifest %&gt;% \n  mutate(\n    pass.age = floor(\n      time_length(\n        interval(pass.dob, ymd(\"2025-02-10\")),\n        \"years\")\n      )\n  )\n\n\n\n\n\n\n\nNoteDid you know\n\n\n\nHistoric passenger manifests from naval crossings in the late 19th and early 20th centuries are available at the Library and Archives Canada website? You can search the passenger database using dates, ports of departure and arrival, and ship names!\n\n\n\nLibrary and archives Canada image of an historic passenger manifest\n\n\nHere’s an example of a meticulously-collected and beautifully hand-written data set - imagine having to clean and digitize all these records!\n\n\n\n\nStep 4: Fix Province variable\nWe noted already that the Province variable (e.g., home.prov) appears to have been entered inconsistently! Some entries have the full name of the province spelled out, some abbreviated, some abbreviated multiple ways.. needless to say, this needs to be fixed and put into a consistent format, so let’s practice that now.\nThe first thing we’ll want to do is check the variable and extract a list of all the different ways that provinces have been coded. If we were to do this with all the observations in our dataset, though, we’d end up with a very long list that included a lot of redundant entries. Instead - let’s create a non-redundant list first, using another handy tidyverse function: distinct().\nTo do this, we’ll invoke our manifest dataframe, select the “home.prov” variable, then call the distinct() function. E.g.,\n\nmanifest %&gt;% \n  select(\"home.prov\") %&gt;% \n  distinct()\n## # A tibble: 19 × 1\n##    home.prov                \n##    &lt;chr&gt;                    \n##  1 AB                       \n##  2 British Columbia         \n##  3 Quebec                   \n##  4 BC                       \n##  5 Ontario                  \n##  6 QC                       \n##  7 Manitoba                 \n##  8 ON                       \n##  9 Québec                   \n## 10 Nova Scotia              \n## 11 NS                       \n## 12 Alberta                  \n## 13 Prince Edward Island     \n## 14 Saskatchewan             \n## 15 SK                       \n## 16 New Brunswick            \n## 17 Sask                     \n## 18 NFLD                     \n## 19 Newfoundland and Labrador\n\nBased on the above output, we have 19 different versions of province names included, but we definitely do not have 19 different provinces in Canada! You’ll notice as well that Quebec sometimes has an accent, and sometimes does not. Let’s propose to simplify things, and in our final dataset, just use 2-letter abbreviations for provinces.\nThis does mean that we’ll need to identify all the variations present for each province, then replace them with the abbreviated version. To make sure that we can review and verify, we’ll create a new variable with these replacements first, then overwrite our old variable once we’ve checked and verified that things are done correctly.\n\nThe case_when function\nOur current operation is a great time to practice the case_when() function. This function will end up coming in very handy over and over again, so its a good chance for us to get well-acquainted with it now.\nThe function case_when looks for observations or rows in your dataset that evaluate some condition being true, then returns a value when this is found. If you have ever played with “if…then” statements or used the ifelse() function in R - then this will feel very familiar to you. In our scenario - we have observations that may appear to satisfy one of a number of cases, and when this occurs, we want to return another value. We just have to type them out using the following syntax:\n\ncase_when(conditional statement 1 ~ value to return if true,\nconditional statement 2 ~ value to return if true,\nconditional statement 3 ~ value to return if true,\n…(continue with as many statements as you need)\nTRUE ~ value to return if above conditions are FALSE)\n\n\nmanifest &lt;- \nmanifest %&gt;% \n  mutate(home.prov.abb = case_when(\n    home.prov == 'BC' ~ 'BC',\n    home.prov == 'British Columbia' ~ 'BC',\n    home.prov == 'AB' ~ 'AB',\n    home.prov == 'Alberta' ~ 'AB',\n    home.prov == 'SK' ~ 'SK',\n    home.prov == 'Sask' ~ 'SK',\n    home.prov == 'Saskatchewan' ~ 'SK',\n    home.prov == 'MB' ~ 'MB',\n    home.prov == 'Manitoba' ~ 'MB',\n    home.prov == 'ON' ~ 'ON',\n    home.prov == 'Ontario' ~ 'ON',\n    home.prov == 'QC' ~ 'QC',\n    home.prov == 'Quebec' ~ 'QC',\n    home.prov == 'Québec' ~ 'QC',\n    home.prov == 'NS' ~ 'NS',\n    home.prov == 'Nova Scotia' ~ 'NS',\n    home.prov == 'PEI' ~ 'PEI',\n    home.prov == 'Prince Edward Island' ~ 'PEI',\n    home.prov == 'New Brunswick' ~ 'NB',\n    home.prov == 'NFLD' ~ 'NL',\n    home.prov == 'Newfoundland and Labrador' ~ 'NL',\n    TRUE ~ \"missing\"\n    ))\n\nNow, to check whether or not we missed any provinces in the list, let’s filter our new variable, looking for instances of the ‘missing’ entry that we specified as our catch-all.\n\n\nmanifest %&gt;% \n  filter(home.prov.abb == 'missing')\n## # A tibble: 0 × 17\n## # ℹ 17 variables: pass.fname &lt;chr&gt;, pass.lname &lt;chr&gt;, pass.dob &lt;date&gt;,\n## #   pass.age &lt;dbl&gt;, pass.gender &lt;chr&gt;, pass.status &lt;chr&gt;, home.address &lt;chr&gt;,\n## #   home.city &lt;chr&gt;, home.prov &lt;chr&gt;, home.country &lt;chr&gt;,\n## #   emerg.contact.fname &lt;chr&gt;, emerg.contact.lname &lt;chr&gt;,\n## #   emerg.contact.relationship &lt;chr&gt;, emerg.contact.phone &lt;chr&gt;,\n## #   board.date &lt;chr&gt;, board.location &lt;chr&gt;, home.prov.abb &lt;chr&gt;\n\nSince our filter returned zero rows of the home.prov.abb variable that were ‘missing’ (and nothing returned NA), we can rest knowing that our variable is complete. Now we’ll replace the home.prov variable with the one that we created, and remove the temporary variable from the dataset.\nNote: in this example, we’ll use the select() function with a negative operator to specify which variables to drop.\n\n\nmanifest &lt;- \n  manifest %&gt;% \n  mutate(home.prov = home.prov.abb) %&gt;%\n  select(-home.prov.abb)\n\n\n\n\nStep 5: Emergency Contact Information\nLooking through the emergency contact information, we can see that there are several issues with the character strings taking place.\n\nThere are several missing and marked as NA (not much we can do about these at the moment).\nWhen a name includes a professional designation (like “D.D.S.”) then this gets added to the person’s last name. We’ll ignore the strangeness of people using their dentist as their emergency contact, and focus on fixing these for the sake of clean data entry only.\nWhen a name is prefixed with a title (e.g., “Dr.”) the prefix becomes the contact’s first name, and has pushed first and last name into the same variable.\n\n\nThe stringr package\nIssues within variables that contain character-strings are a perfect opportunity to practice with functions from the stringr package. No need to load anything new - stringr contains some very useful data-cleaning tools for character data, including the function str_replace() which will allow us to modify character strings using a pattern and replacement strategy.\nSince we want to affect all the entries in the variable, we’ll use the version of the function str_replace_all() which can modify all entries at once, rather than seeking just the first entry that meets our criteria. The inputs for str_replace_all() are as follows:\n\nstr_replace_all(string, pattern, replacement)\n\n\nstring = the variable containing character strings you wish to modify\npattern = the pattern you want to replace\nreplacement = the character string to be used as the replacement\n\nLet’s use the function now to modify the emergency contact first and last name fields. We need to remove the titles “Mr.”, “Mrs.”, and “Dr.”, so we’ll just replace them with an empty string: ““. We’ll do the same thing to the suffixes in the last-name field, replacing DDS and Jr. with”“.\nYou’ll notice in the code below that we use a double-escape (\\\\) before a period. This is because stringr functions use regex (regular expressions) conventions as wildcards, and the period (.) is a wildcard for anything. So if we didn’t escape the character ‘.’ in ‘Dr.’ for example, then R will look for the string ‘Dr’ followed by any string of any length, and we don’t want that.\nRegex is a deep and powerful toolset that we encourage you to check out, should you be interested in it, however, we will not be covering it any further in this course.\nLet’s try writing out the code for prefixes and suffixes. We’ll call our manifest dataframe, use mutate() to let R know we’re affecting change on a variable, in this case emerg.contact.fname and emerg.contact.lastname, then specify our string replacements using str_replace_all().\n\nmanifest &lt;- \nmanifest %&gt;%\n  mutate(emerg.contact.fname =\n           str_replace_all(\n             string = emerg.contact.fname,\n             pattern = \"(Mr\\\\.|Mrs\\\\.|Dr\\\\.)\",\n             replacement = \"\")\n         ) %&gt;%\n  mutate(emerg.contact.lname = \n           str_replace_all(\n             string = emerg.contact.lname,\n             pattern = \"(DDS|Jr\\\\.)\",\n             replacement = \"\")\n         )\n\nGreat work! We’re almost done with this step, all that is left to do now, is to fix the squished names present in the emerg.contact.lname variable. Let’s discuss two approaches.\n\nWe could spend some time figuring out a regular expression to separate text based on letter case. In this instance, we would be looking for the position in the string that changes from lower case to upper case. E.g., DavidSmith –&gt; David | Smith. However, remember that we’re applying this function to the entire variable, and if our syntax isn’t 100% correct, we could inadvertently introduce more errors into the mix.\nInstead, we recommend fixing the entries explicitly, using the exact examples that need fixing. This may seem slightly more tedious, but in this example, it is far safer, and will save us from a lot of headache if our code in option 1 doesn’t function the way we expect it to.\n\nWith this in mind, lets specify the first-names we want to replace in the emerg.contact.fname variable based on the emerg.contact.lname variable, then fix the last names once that’s done.\n\nmanifest &lt;- \nmanifest %&gt;% \n  mutate(emerg.contact.fname = \n           case_when(emerg.contact.lname == \"DavidSmith\" ~ \"David\",\n                     emerg.contact.lname == \"GeorgeBooker\" ~ \"George\",\n                     emerg.contact.lname == \"DouglasEvans\" ~ \"Douglas\",\n                     emerg.contact.lname == \"JacobScott\" ~ \"Jacob\",\n                     emerg.contact.lname == \"ToniAvila\" ~ \"Toni\",\n                     TRUE ~ emerg.contact.fname\n                     ),\n         emerg.contact.lname = \n           case_when(emerg.contact.lname == \"DavidSmith\" ~ \"Smith\",\n                     emerg.contact.lname == \"GeorgeBooker\" ~ \"Booker\",\n                     emerg.contact.lname == \"DouglasEvans\" ~ \"Evans\",\n                     emerg.contact.lname == \"JacobScott\" ~ \"Scott\",\n                     emerg.contact.lname == \"ToniAvila\" ~ \"Avila\",\n                     TRUE ~ emerg.contact.lname))\n\n\n\n\nStep 6: Fix boarding date.\nThe last thing to do to get our dataset into tip-top shape is to fix the boarding date variable. Since there’s only two variations in this one (e.g., Feb 9th and Feb 10th) this should be an easy fix using our case_when() function. Keep in mind, however, that we may want to be able to use this variable in calculations later, so we should also restore it to a date format using Lubridate’s ymd() function.\nLet’s wrap these together into one operation:\n\nmanifest &lt;- \nmanifest %&gt;% \n  mutate(board.date = case_when(\n    board.date == \"Feb 9th\" ~ ymd('2025-02-09'),\n    board.date == \"Feb 10th\" ~ ymd('2025-02-10'),\n    TRUE ~ NA)\n  )\n  \n\n\n\nSaving your dataset to disk\nHave a look through your dataset with the view() function, and make sure that everything looks correct. When you’re ready to save the final dataset to a file on your computer, use the write_csv() function like so:\n\nwrite_csv(dataset, “name_to_save_as.csv”)"
  },
  {
    "objectID": "module01.html#summary",
    "href": "module01.html#summary",
    "title": "Module 1",
    "section": "Summary",
    "text": "Summary\nCongratulations! At this point, you have successfully cleaned up the ship’s manifest, enabling further analysis, and recording a number of really important transformations.\nYou managed to do all of the following, using only tidyverse functions:\n\nRead a complex excel file and store it as a data frame object\nRemove egregious excel-formatting from the header of the file\nFix variable names\nFix individual data entries within variables\nFix dates\nFix complex strings\nWrite a file to disk.\n\nThat’s a lot! We even managed to sneak a small preview of regular expressions in there!"
  },
  {
    "objectID": "module01.html#quiz",
    "href": "module01.html#quiz",
    "title": "Module 1",
    "section": "Quiz",
    "text": "Quiz\nLet’s do a quick review of the Tidyverse functions we used in this module:\n\n\n\n\n1. What does mutate() do?\n\nRemoves rows from a data frame Creates or modifies columns Joins two datasets Submit\n\n\n\n\n\n2. In case_when(), what does the final TRUE ~ x line usually mean?\n\nConvert TRUE values to missing Leave unmatched values unchanged Drop all rows that evaluate to TRUE Submit\n\n\n\n\n\n3. What does ymd() from lubridate do?\n\nConverts strings into Date objects using year–month–day order Extracts the year from a date Randomly shuffles date values Submit\n\n\n\n\n\n4. What is a common use of str_replace_all()?\n\nReplace all occurrences of patterns in a string Split a string into tokens Convert character vectors to factors Submit\n\n\n\n\n\n5. What does select() do?\n\nFilter rows based on a logical condition Choose columns to keep, drop, or rename Convert a data frame into long format Submit\n\n\n\n\n\n6. What does distinct() return?\n\nAll duplicated rows A data frame with unique rows (or unique combinations of selected columns) A list of duplicated column names Submit\n\n\n\n\n\n7. What does a lubridate interval() represent?\n\nA sequence of equally spaced dates A duration of time measured in seconds A precise time span with a fixed start and end datetime Submit\n\n\n\n\n\n8. What does glimpse() do?\n\nPrints the structure of a data frame in a horizontal, tidy format Creates a histogram of numeric variables Converts a data frame into a tibble Submit"
  },
  {
    "objectID": "module03.html",
    "href": "module03.html",
    "title": "Module 3",
    "section": "",
    "text": "Welcome back!\nSo far in the course, we’ve gotten used to navigating our datasets using Tidyverse functions.\nIn this module, we’ll be practicing another critical skill: working with multiple datasets!"
  },
  {
    "objectID": "module03.html#scenario-update",
    "href": "module03.html#scenario-update",
    "title": "Module 3",
    "section": "Scenario update",
    "text": "Scenario update\nBlarney! It’s a good thing that D.N.P. cruise-lines thought to hire an epidemiologist for their voyage! Passengers with symptoms of abdominal pain or worse have been reporting to the ship’s infirmary like crabs to catfood! Something isn’t sitting well on this boat, and you’ve got a sneaky suspicion that you might be facing an on-board outbreak.\nYou can’t make bricks without clay, however, and we cannot make conclusions without evidence. We’ll need to do some basic epidemiology to assess if there are any commonalities between the sick passengers before we can report our recommendations to the captain.\nThankfully, the ship’s nurse has been quite co-operative and provided you with the records of individuals that have reported to the infirmary over the last few days. Upon opening the email and giving it a quick scan, however, you realize that none of the demographic information (e.g., age, sex) has been included in the data. In fact, it turns out that the nurse aboard the S.S. Rainbow Cake takes personal data confidentiality VERY SERIOUSLY, and passenger names aren’t even included!\nInstead of names, passenger health data have been coded to use a personal identification number (PIN). Lucky for us, the nurse keeps a copy of the ship’s manifest, and recorded a PIN for each passenger, but these datasets are separate, and you’ll need to find a way to combine them in order to figure out who’s who! Good thing you’ve been practicing data appends and joins!"
  },
  {
    "objectID": "module03.html#learning-objectives",
    "href": "module03.html#learning-objectives",
    "title": "Module 3",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of Module 3, you will be able to\n\nDescribe your plan for combining multiple datasets together.\nCombine multiple datasets using Tidyverse syntax.\nExplain use-cases for several different types of data-join operations."
  },
  {
    "objectID": "module03.html#part-a-exploring-datasets-and-mapping-out-a-data-collation-plan",
    "href": "module03.html#part-a-exploring-datasets-and-mapping-out-a-data-collation-plan",
    "title": "Module 3",
    "section": "Part A: Exploring datasets and mapping out a data collation plan",
    "text": "Part A: Exploring datasets and mapping out a data collation plan\nIn this module, you’ve been given several datasets that you’ll want to combine in order to calculate some summaries.\nFirst, however, you’ll need to review what data you’ve been provided with, and formulate a strategy for combining datasets in a way that makes most sense for the types of analyses you’ll want to do.\n\nAbdo datasets\nIn your Module3 datsets folder you should see the following files, that correspond to data extracts related to passengers with abdominal pain complaints:\n\nabdo_Feb10.tsv\nabdo_Feb11.tsv\nabdo_Feb12.tsv\nabdo_Feb13.tsv\nabdo_Feb14.tsv\n\nEach of the abdo_ files are formatted the same way and contain data collected on a single date. These files were extracted from the infirmary’s database, and contain several rows of metadata at the top of the file that you’ll want to filter out. They also all contain the following variables:\n\nData dictionary for data extracts from the ship infirmary\n\n\n\n\n\n\nVariable\nDefinition\n\n\n\n\nPass_ID\nUnique identifier given to ship passengers\n\n\nRecorded temperature\nOral temperature taken during medical visit (degrees celsius)\n\n\nRecorded height\nPassenger height measurements taken during medical visit (cm)\n\n\nRecorded weight\nPassenger weight measurement taken during medical visit (kg)\n\n\nCEDIS\nCEDIS Chief complaint code, input by nurse at check-in (see additional handout)\n\n\n\n\n\nPassenger manifest\nThe ship’s nurse has also provided you with a copy of their passenger manifest - which thankfully has the Pass_ID included, as well as the demographic information you’ll need to summarize the epidemiology of passengers experiencing symptoms of illness.\nAlso - lucky us, it seems as though the ship’s infirmary does a much better job of maintaining the passenger manifest as well! So we shouldn’t have to worry about cleaning it a second time. There are, however, more variables than we really need for answering our questions about who is getting sick - so we’ll want to focus just on the variables pertinent to our analysis. Lets focus on keeping the following:\n\nVariables to keep from the passenger manifest\n\n\n\n\n\n\nVariable\nDefinition\n\n\n\n\nPass_ID\nThe unique identifier given to each passenger by the crew of the S. S. Rainbow Cake.\n\n\nAge\nAge of the passenger at the time of the cruise departure.\n\n\nGender\nReported gender of the passenger.\n\n\nMember status\nWhich tier of rewards member. May determine access to different amenities or food items.\n\n\nBoarding date\nWhat date the passenger boarded the cruise ship.\n\n\n\n\n\nData collation plan\nNow that we have an idea about what our datasets will look like, we should sketch out a strategy for how our data sets can be joined together. Starting with our abdo datasets: these are all in the same format, but separated out for each day. We’ll want to append these datasets together, and create a new variable to indicate what the date was that the symptoms were reported.\nFor our append operation, we’ll be using the following function:\n\nbind_rows(dataset1, dataset2, etc..., .id = \"id\")\n\nSimply, bind_rows will combine our data by stacking the rows on top of each other. Its important to ensure that all the column names are consistent, otherwise we’ll get a messy bunch of rows with mostly NA’s in them.\nThe argument .id=“id” will produce a new column that contains a character string of the filename. This will then let us identify which observations were recorded on each day, and we can then mutate() a new column based on this to represent the onset date.\n\n\n\nUsing bind_row() to append the abdo datasets into one.\n\n\nOnce we have a working abdo dataset in place, we can turn our attention to the passenger manifest file. This manifest has already been cleaned by the ship’s staff, and contains the unique passenger ID variable that we can use as a key variable. The dataset is, however, still saved as an Excel workbook, and contains the messy header and extraneous variables - so you’ll need to revisit how we imported this properly in Module 1 if you’ve forgotten, and then select the variables to keep from the table above. When that’s done, we’ll join the two tables together with the key variable.\n\n\n\nCollating abdo and manifest datasets using table join\n\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure that you think about what table join is the most appropriate for the end result you’re hoping to achieve! Also, the order that you specify the tables matters with some table joins! If you need help remembering how each of the different join types work, refer to the references on mutating joins and filtering joins!\n\n\n\n\nCode-along for Part A\nIf you’re feeling confident, then we encourage you to try establishing the code yourself for this exercise. However, we’ve provided the code that we used below. Remember, there’s always multiple ways to accomplish the same thing, so don’t worry if your code doesn’t always match what we’ve done!\n\nImporting and appending the Abdo datasets\n\n\n# Load required libraries\n# library(pacman)\n# p_load(tidyverse)\n\n\n# create a vector to store consistent and simple variable names for abdo datasets\nabdo_names &lt;- c(\"pass.ID\", \"pass.temp\", \"pass.height\", \"pass.weight\", \"CEDIS\")\n\n\n# load abdo datasets using read_tsv from the readr tidyverse package: \nabdo_feb10 &lt;- read_tsv(\"participant_data/module3/abdo_Feb10.txt\", col_names = abdo_names, skip = 4)\nabdo_feb11 &lt;- read_tsv(\"participant_data/module3/abdo_Feb11.txt\", col_names = abdo_names, skip = 4)\nabdo_feb12 &lt;- read_tsv(\"participant_data/module3/abdo_Feb12.txt\", col_names = abdo_names, skip = 4)\nabdo_feb13 &lt;- read_tsv(\"participant_data/module3/abdo_Feb13.txt\", col_names = abdo_names, skip = 4)\nabdo_feb14 &lt;- read_tsv(\"participant_data/module3/abdo_Feb14.txt\", col_names = abdo_names, skip = 4)\n\nGreat! Notice that we used skip = 4 to remove the header row, since we’ve stipulated our own headers in the abdo_names vector.\nNext, let’s append these datasets together using the bind_rows() function.\n\n\nabdo_combined &lt;- bind_rows(abdo_feb10,\n                           abdo_feb11,\n                           abdo_feb12,\n                           abdo_feb13,\n                           abdo_feb14,\n                           .id = \"id\")\n\nNow that we have our combined abdo dataset, we can go ahead and mutate a new column based off our ‘id’ variable that was created when we used bind_rows. For this, we’ll revisit the case_when and ymd functions as well from Module 1.\n\nabdo_combined_onset &lt;- \nabdo_combined %&gt;% \n  mutate(onset.date = case_when(\n    id == \"1\" ~ ymd('2025-02-10'),\n    id == \"2\" ~ ymd('2025-02-11'),\n    id == \"3\" ~ ymd('2025-02-12'),\n    id == \"4\" ~ ymd('2025-02-13'),\n    id == \"5\" ~ ymd('2025-02-14')\n  ))\n\nNow we can drop the “id” variable from our abdo_combined_onset dataset, and proceed to joining this dataset with our passenger manifest.\n\n\nabdo_combined_onset &lt;- \n  abdo_combined_onset %&gt;% select(-id)\n\nBefore moving onto the passenger manifest, however, let’s clean up our workspace and remove the temporary objects that we created up till now.\n\n\nrm(abdo_combined, abdo_feb10, abdo_feb11, abdo_feb12, abdo_feb13, abdo_feb14, abdo_names)\n\nGreat - we should be just left with the abdo_combined_onset object in your work session now.\n\n\nImporting the passenger manifest\nNow that we have our abdo dataset all ready to go, we can turn our attention to the updated passenger manifest file. In your Module 3 data folder, you should find the following file:\n\npass_manifest.xlsx\n\nFirst, open this file in Excel and give it a look-through. It should look very familiar to the manifest that you worked on in Module 1, but the data cleaning issues identified in Module 1 have been cleaned up and the passenger ID variable has been added. Remember, you’ll still need to remove the header while importing this file!\n\n# Import the dataset using readxl\n# Note the readxl::read_excel allows for you to access functions from installed \n# packages without loading the entire package. \npass_manifest &lt;- readxl::read_excel(\"participant_data/module3/pass_manifest.xlsx\", \n                            skip = 10)\n\nNow, recall earlier that we determined that we didn’t need to keep all of the data from the passenger manifest, so let’s use the select() function to choose only the variables that we want to keep.\n\npass_manifest_trunc &lt;- #truncated, temporary object\npass_manifest %&gt;% \n  # Note that we wrap variables with spaces in a back-tick\n  select(Pass_ID, Age, Gender, `Member Status`, `Boarding Date`)\n\nWe should have everything we need now to join these two datasets together!\n\n\nDeciding on a join type to combine the two datasets\nNow that we’re at the stage where we will actually join these datasets together, we need to carefully consider which join type we’ll want to use. Remember that there are both mutating joins - which change the data, but don’t drop observations, and filtering joins, which DO drop observations.\nTo help you decide which join you want - think through the following questions:\n\nWhat question are you ultimately trying to answer?\nDo you need all the data from both datasets?\nWhich dataset contains the observations most important to you, and which dataset contains the supplementary information you’re trying to add?\n\n\n\nClick to see our decision and reasoning\n\nFor this operation, we decided that a left_join would work best!\n\nA left join (left_join()) keeps all rows from the left (first) data frame, and adds matching columns from the right data frame based on the join key(s).\nIf a row in the left data frame has no matching key in the right, the new columns are filled with NA.\nRows in the right data frame that don’t match any left-side keys are dropped and do not appear in the result.\nSince we’re interested in the cases reporting abdominal symptoms primarily, and we’re looking to add supplementary demographic data, the left join makes the most sense, and keeps the results nice and tidy for us, without any extras.\n\n\n\n\n\n\n\nWarning\n\n\n\nDon’t forget that the order of tables matters when invoking left_join().\n\n\n\n\n\nJoining the final abdo and passenger manifest datasets\nThis is it! We’ve made it to the step where we finally get to join these datasets together into one, using the join type that we decided upon. Let’s take a quick look at the syntax for left_join().\n\nleft_join(x, y, by = ...)\n\n\nx is the table for which all the rows will be kept\ny is the table that you want to add data from\nby is an optional argument that specifies the key value to join the datasets on. Since we have “pass.ID” in the abdo dataset, and “Pass_ID” in the manifest, we have to let R know that these are common variables between the two tables.\n\n\n\n# Time to join these datasets together! \n\nabdo_manifest &lt;- left_join(abdo_combined_onset, pass_manifest_trunc, by = c(\"pass.ID\" = \"Pass_ID\"))"
  },
  {
    "objectID": "module03.html#part-b-separating-pivoting-and-rejoining-data",
    "href": "module03.html#part-b-separating-pivoting-and-rejoining-data",
    "title": "Module 3",
    "section": "Part B: Separating, pivoting, and rejoining data",
    "text": "Part B: Separating, pivoting, and rejoining data\nLet’s recap where we’re at so far:\n\nAccording to our abdo_manifest dataset, as of Feb 14th, we have 69 passengers aboard the S.S. Rainbow Cake who have fallen ill, reporting symptoms of abdominal pain or worse.\nWe have established onset dates for each of the ill passengers by appending the individual abdo datasets together and establishing the date that they reported to the ship infirmary as a variable in our dataset.\nBy joining the combined abdo dataset with a version of the passenger manifest that has a unique identifier assigned to each passenger, we were able to securely import demographic variables and attach them to the appropriate passengers.\n\nRecall the reason that we completed these steps was so that we could produce some epidemiological summaries about the sick passengers, and establish whether or not there may be commonalities between symptoms and some characteristics about the individuals.\nAt present, we have our dataset of cases who reported at least abdominal pain, we’ve established their onsets from the reporting date, and we’ve joined our data with the demographic variables present from the passenger manifest!\nNow it’s time that we address the manatee-in-the-room: the CEDIS variable! All of our symptom data are actually being stored in this one variable, coded using the Canadian Emergency Department Information Systems approach! Nurse Hookhand has once again shown her flair for data management!\n\n\n\n\n\n\nNoteDid you know\n\n\n\nThe Canadian Emergency Department Information System (CEDIS) is a Canadian initiative to provide a systematic approach to data collection across hospital emergency departments nation-wide. The system was established through a collaborative, consensus based approach, and included input from hospital nurses, administrators, and researchers all across Canada. The goals of the approach were to create a system of systematically capturing and categorizing chief complaints in emergency departments and triage settings to facilitate clinical care, research and emergency department management with a specific, Canadian healthcare-system context.\nCool facts about CEDIS:\n\nCEDIS presenting complaint data are commonly used for syndromic surveillance systems (e.g., in Yukon, Yukon’s ED-SyS uses CEDIS codes from real-time ED data).\nPublic health applications often rely on presenting complaints because they are completed promptly at triage, whereas discharge diagnosis codes may lag or be incomplete. Evidence from BC COVID-19 ED use analysis notes that CEDIS presenting complaints often have more complete coverage and are used for surveillance.\nCEDIS is integrated into NACRS for national reporting, enabling linking to other health administrative data.\n\nReferences\nInnes G, Murray M, Grafstein E. A consensus-based process to define standard national data elements for a canadian emergency department information system. Canadian Journal of Emergency Medicine. 2001;3(4):277-283. doi:10.1017/S1481803500005777\nBouchouar E, Hetman BM, Hanley B. Development and validation of an automated emergency department-based syndromic surveillance system to enhance public health surveillance in Yukon: a lower-resourced and remote setting. BMC Public Health. 2021 Jun 29;21(1):1247. doi: 10.1186/s12889-021-11132-w. PMID: 34187423; PMCID: PMC8240073.\nYao, J., Irvine, M. A., Klaver, B., Zandy, M., Dheri, A. K., Grafstein, E., & Smolina, K. (2023). Changes in emergency department use in British Columbia, Canada, during the first 3 years of the COVID-19 pandemic. CMAJ, 195(34), E1141–E1150. https://doi.org/10.1503/cmaj.221516\nCanadian Institute for Health Information. (2025). National Ambulatory Care Reporting System (NACRS) metadata. https://www.cihi.ca/en/national-ambulatory-care-reporting-system-nacrs-metadata\nCanadian Association of Emergency Physicians. (n.d.). Canadian Emergency Department Information System (CEDIS). https://caep.ca/resources/cedis/\n\n\n\nConverting the CEDIS variable into useful symptom data\nWhile there is undoubtedly rich information contained in the CEDIS variable, we’re going to have to think through what type of operations we’ll need to extract and use the information provided. Let’s list some considerations below.\n\nCEDIS codes are stored as 3-digit numbers. We have provided a PDF of the numeric translation in the folder for Module 3. You will need to translate the codes into the symptoms they represent in order to make sense of the data and summarize the reported symptoms.\nCodes are stored in a single variable, and multiple codes have been separated by a semi-colon. We’ll need to separate these out first into separate variables to facilitate using them in summaries.\nNot everyone reported the same number of symptoms, so whatever we do for the step above needs to ensure that the correct symptom code is reported to the correct variable, and only that variable.\n\nWe’ll start by tackling steps 2 and 3 first, then go back and figure out step 1.\n\n\nPlanning our approach\nTidyverse has some very useful functions that will enable us to separate out values from our CEDIS value and redistribute them into their own variables. We’ll walk through and explain some example code here - but as always, feel free to skip ahead and attempt to figure out the coding on your own if you feel comfortable doing so! There are more sophisticated and quicker ways to perform the operations than what we’ll show here, so if you have a better way to get the same results with the CEDIS data, please do so!!\nConceptually the approach that we’ll take will follow something like this:\n\nWe’ll start by working with a simplified subset of our data that only includes the passenger ID (pass.ID) and the CEDIS variables.\nWe’ll turn each pass.ID x CEDIS code into a separate row (i.e., multiple rows per individual, with only one CEDIS code present in the CEDIS variable) using the separate_rows() function.\nWe’ll then use the pivot_wider() function to stretch the CEDIS data from long-format into wide-format.\nWe’ll rename the variables based on the associated symptoms.\nFinally we’ll re-join these data back to our original table.\n\n\n\n\nData flow diagram for working with the CEDIS variable\n\n\n\n\nCode-along for Part B\nFirst, we’ll start by saving a temporary subset of our abdo-manifest object that contains only the pass.ID and CEDIS variables. This will help to ensure that we don’t mistakenly manipulate other variables in our dataset accidentally.\n\n\n\nCEDIS_subset &lt;- abdo_manifest %&gt;%\n  select(pass.ID, CEDIS)\n\n\nApply separate_rows()\nEasy enough, next, let’s check out the arguments we’ll need to specify in the separate_rows() function:\n\nseparate_rows(data, … , sep, convert)\n\n\ndata = the data frame we want to modify (this is already handled with the %&gt;% operator)\n… = tidy-select columns we want to target\nsep = the character used to separate the values we want to split up (e.g., “;”)\nconvert = (T/F) this tells R whether or not we want to convert the resulting columns into whatever class the individual values are. For example, the CEDIS variable is presently stored as a character string because it mixes both numeric and character values. If we set convert = T, then the separated CEDIS codes will be treated as numeric, and if we set convert = F, then they’ll stay as characters.\n\n\n\n\n\n\n\nWarning\n\n\n\nNote: the Tidyverse team has marked separate_rows() as end of lifecycle / deprecated. This doesn’t mean that the function won’t continue to work, but it does mean that the team will not continue to update it. The function that is intended to replace it is called separate_longer_delim(), however, it is still in experimental status, so we won’t official move to that one until a later time.\n\n\nLet’s hit the CEDIS variable with our separate_rows() function and see what we get!\n\nCEDIS_subset_long &lt;- \nCEDIS_subset %&gt;%\n  separate_rows(CEDIS, sep = ';', convert = FALSE)\n\n#view(CEDIS_subset_long)\n\n\n\nApply pivot_wider()\nNow we can use the pivot_wider() function to create new variables based on the values present in the CEDIS variable.\n\npivot_wider(id_cols, names_from, values_from, values_fill)\n\n\nid_cols = the key or identity variable, in this case, pass.ID\nnames_from = the variable containing the names that will be used for new variables\nvalues_from = the variable that contains the data you want to use to fill in under the new variable headings\nvalues_fill = a ‘fill’ value to be used to fill in the missing observations (e.g., 0, NA, etc.)\n\n\n\n\n\n\n\nWarning\n\n\n\nNote: pivot_wider() assumes that each combination of the id_cols and names_from variables is unique. If duplicates exist in your dataset (e.g., two instances of pass.ID = 001 and CEDIS = 251), you must specify a function using values_fn() to define how those duplicate values should be handled (e.g., max for presence/absence, sum for counts).\n\n\n\nCEDIS_subset_wide &lt;- \nCEDIS_subset_long %&gt;% \n  mutate(value = 1) %&gt;%\n  pivot_wider(id_cols = pass.ID,\n              names_from = CEDIS,\n              values_from = value,\n              values_fill = 0)\n\n\n\nRename() variables\nOn to the easy part! We now just have to rename the CEDIS codes into useful variable names!\nTake a few minutes to review the CEDIS table that was provided in your participant folder and note down the symptoms that correspond with each of the codes.\n\n\nClick to see the codes\n\nJust kidding! You didn’t think we’d do all the work for you, did you?\nTake a break from your RStudio console and give the PDF a quick read, you should be easily able to find the symptoms that correspond to the following CEDIS codes:\n\n251\n254\n257\n260\n404\n\n\n\nNeed a short brain-break? Every thought about the differences between R and Python? Here’s a short video where Posit’s Chief Data Scientist, Dr. Hadley Wickham, talks about R versus Python.\n\n\n\nR versus Python - more alike than different!\n\n\n\nOk - on to the coding step. If you still haven’t looked up the codes at this point - then follow along and see how we decided to rename the variables.\nThe rename() function allows you to specify exactly which variables you want to rename, and uses a “new.name” = “old.name” syntax. When you’re working with more complex datasets, or in the middle of a series of operations, its generally much safer to rename variables this way.\n\n\nsymptoms_table &lt;- \nCEDIS_subset_wide %&gt;% \n  rename(\"abdo.pain\" = \"251\",\n         \"vomiting\" = \"257\",\n         \"diarrhea\" = \"254\",\n         \"bloody.stool\" = \"260\",\n         \"headache\" = \"404\")\n\n\n\nJoin() with main dataset\nFinally it’s time to join our symptoms data back with our main manifest!\nLet’s go ahead and re-unite these data, using the pass.ID as the key variable! Note that this time, since the key variable is named the same in both datasets, we don’t actually need to specify the variable in our list of function arguments.\n\n\nsymptoms_manifest &lt;- full_join(symptoms_table, abdo_manifest)\n\n# Remove all but the specified objects from memory\n#rm(rm(list = setdiff(ls(), c(\"symptoms_manifest\"))))\n\nReview your symptoms manifest object to ensure that everything looks in order. Once that’s finished, clean up your workspace, removing any of your temporary/intermediate data objects."
  },
  {
    "objectID": "module03.html#part-c-youre-an-epidemiologist-remember",
    "href": "module03.html#part-c-youre-an-epidemiologist-remember",
    "title": "Module 3",
    "section": "Part C: You’re an epidemiologist, remember?",
    "text": "Part C: You’re an epidemiologist, remember?\nAlright - up until now we’ve focused primarily on cleaning and manipulating data, which are essential skills for an epidemiologist to have. However, you were hired aboard the S. S. Rainbow Cake because you’re an epidemiologist and are trained to think about how data are used to solve public health issues, so let’s turn our focus now to exploring what are our data are telling us.\nWe need a tool to help turn our observations into meaningful summaries, and the summarize() family of functions will provide just that!\nThe summarize() function takes your specified data and summary functions (e.g., sum, mean, median, max, min, etc.) as input, and outputs a new data frame with the results stored as variables. The syntax should look fairly familiar at this point.\ne.g.,\n\ndata %&gt;% summarize(\nsummary_mean = mean(variable),\nsummary_median = median(variable),\nsummary_example3 = some.function(variable),\netc.\n)\n\nA very useful supplement to summarize() functions is the ability to group your data prior to the summaries being calculated. This allows you to create a summary of one variable for each level of another variable. E.g., calculating the median age for females and males separately.\nYou can group variables in one of two ways.\n\nUsing the .by = argument inside the summarize() function. E.g., adding .by = Gender will split your data into groups of males and females only before carrying out the summary function indicated.\nUsing group_by() before invoking summarize() in your tidyverse pipe operations. E.g.,\n\n\ndata %&gt;%\ngroup_by(grouping.variable) %&gt;%\nsummarize(mean = mean(summary.variable),\nmedian = median(summary.variable),\netc.)\n\nLet’s list some summaries that we may be interested in, then work up an example using summarize().\nSimple statistics to summarize:\n\nMean, median and range of ages for all cases\nNumbers of total male and female cases\nNumbers of passengers with fever (e.g., &gt; 38 degrees Celsius)\nTotal numbers of cases reporting\n\nVomiting\nDiarrhea\nHeadache\nBloody stool\n\n\n\nMean, median and range of ages\nLet’s first look at a description of cases in the data:\n\n\nsymptoms_manifest %&gt;% \n  summarize(.by = Gender,\n    mean_age   = mean(Age, na.rm = TRUE),\n    median_age = median(Age, na.rm = TRUE),\n    max_age    = min(Age, na.rm = TRUE),\n    min_age    = max(Age, na.rm = TRUE)\n  )\n## # A tibble: 2 × 5\n##   Gender mean_age median_age max_age min_age\n##   &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n## 1 Female     48.6       44.5      12      86\n## 2 Male       53.3       50        15      85\n\nIt doesn’t appear that there are any differences in the age distribution of female and male cases based on what we see here.\n\n\nNumber and proportions of female vs. male cases\nNext, let’s tally the total number of female and male cases, and calculate their proportions as well.\n\n\nsymptoms_manifest %&gt;% \n  group_by(Gender) %&gt;%\n  summarize(Total = n(),\n            Proportion = n()/sum(Total))\n## # A tibble: 2 × 3\n##   Gender Total Proportion\n##   &lt;chr&gt;  &lt;int&gt;      &lt;dbl&gt;\n## 1 Female    40          1\n## 2 Male      29          1\n\nWhoops! What do you notice above about our results? The proportion is returning the total number of female cases out of the total number of female cases, and vice-versa for males. This is because our .groups remain in effect in the summarize() function until we say otherwise. To get the correct proportions, we’ll need to adjust our code.\n\n\nsymptoms_manifest %&gt;% \n  group_by(Gender) %&gt;%\n  summarize(Total = n(), .groups = \"drop\") %&gt;%\n  mutate(Proportion = Total / sum(Total))\n## # A tibble: 2 × 3\n##   Gender Total Proportion\n##   &lt;chr&gt;  &lt;int&gt;      &lt;dbl&gt;\n## 1 Female    40      0.580\n## 2 Male      29      0.420\n\nIn the above summarize() call, we’ve told R that groups should be dropped in the result, and then used the Total variable to mutate a new variable that returns the proportion of the sum of the total for each female and male cases. This time, it works as expected.\n\n\nCases reporting with Fever\nFor this one, we’ll use mutate a new variable called “Fever” based on the temperature values, and then calculate the summaries based on that. Let’s go with anything over 38 degrees constituting a fever.\n\n\nsymptoms_manifest &lt;- \n  symptoms_manifest %&gt;% \n  mutate(Fever = case_when(\n    pass.temp &gt; 38.0 ~ 1, \n    pass.temp &lt;= 38.0 ~ 0, \n    TRUE ~ NA\n  ))\n\n\nsymptoms_manifest %&gt;% \n  count(Fever)\n## # A tibble: 2 × 2\n##   Fever     n\n##   &lt;dbl&gt; &lt;int&gt;\n## 1     0    31\n## 2     1    38\n\nHmm. Interesting - a little over half of our cases with abdominal pain were running a fever. Lets create some age groupings so that we can look a little more closely at age breakdowns.\n\nsymptoms_manifest &lt;- \nsymptoms_manifest %&gt;%\n  mutate(\n    age.group = case_when(\n      Age &lt; 12 ~ \"0–11\",\n      Age &lt; 18 ~ \"12–17\",\n      Age &lt; 30 ~ \"18–29\",\n      Age &lt; 50 ~ \"30–49\",\n      Age &lt; 65 ~ \"50–64\",\n      Age &gt;= 65 ~ \"65+\",\n      TRUE ~ NA\n    )\n  )\n\n\nsymptoms_manifest %&gt;%\n  group_by(age.group) %&gt;%\n  count(Fever)\n## # A tibble: 8 × 3\n## # Groups:   age.group [5]\n##   age.group Fever     n\n##   &lt;chr&gt;     &lt;dbl&gt; &lt;int&gt;\n## 1 12–17         0     2\n## 2 18–29         1     4\n## 3 30–49         0    12\n## 4 30–49         1    18\n## 5 50–64         0     9\n## 6 50–64         1     7\n## 7 65+           0     8\n## 8 65+           1     9\n\n\n\n\n\n\n\nNote\n\n\n\nIt looks like ages 30-49 were experiencing fever most frequently. Does this give us any clues at this stage as to what we might be dealing with? Why or why not?\n\n\nNow let’s look at our remaining symptoms by gender and by age group:\n\nVomiting\nDiarrhea\nHeadache\nBloody Stool\n\n\n\nsymptoms_manifest %&gt;%\n  group_by(Gender) %&gt;%\n  summarize(\n    Vomit = sum(vomiting),\n    Diarrhea = sum(diarrhea),\n    Headache = sum(headache), \n    Bloody.Stool = sum(bloody.stool)\n  )\n## # A tibble: 2 × 5\n##   Gender Vomit Diarrhea Headache Bloody.Stool\n##   &lt;chr&gt;  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n## 1 Female    32       39       31           19\n## 2 Male      24       27       23           12\n\n\nsymptoms_manifest %&gt;%\n  group_by(age.group) %&gt;%\n  summarize(\n    Vomit = sum(vomiting),\n    Diarrhea = sum(diarrhea),\n    Headache = sum(headache), \n    Bloody.Stool = sum(bloody.stool)\n  )\n## # A tibble: 5 × 5\n##   age.group Vomit Diarrhea Headache Bloody.Stool\n##   &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;\n## 1 12–17         2        2        2            0\n## 2 18–29         3        4        3            4\n## 3 30–49        24       29       23           13\n## 4 50–64        15       14       12            5\n## 5 65+          12       17       14            9\n\nHave a look at the results of the symptom breakdown by gender and age. Does anything stand out to you? Why or why not? What age ranges are the majority of your cases in? Is this any different than the general population on the ship?\n\n\nSymptom onset dates\nWe’ll take a look next at symptom onset dates, and see if there’s any discernible pattern that we can identify from the summaries.\n\n\nsymptoms_manifest %&gt;%\n  group_by(onset.date) %&gt;%\n  count() \n## # A tibble: 5 × 2\n## # Groups:   onset.date [5]\n##   onset.date     n\n##   &lt;date&gt;     &lt;int&gt;\n## 1 2025-02-10     4\n## 2 2025-02-11    22\n## 3 2025-02-12    28\n## 4 2025-02-13    13\n## 5 2025-02-14     2\n\nAre you starting to see a pattern here? These numbers appear to read very much like an outbreak curve typical of a point-source exposure.\nLet’s plot these numbers using the ggplot() function so that we can have a quick visualization.\n\n\n\n\n\n\nNote\n\n\n\nThis course is not intended for training an in-depth focus on data visualizations, as that is the focus of another of TDU’s trainings: R for Data Visualization. In this module, we’ll introduce the very basics of summarizing data and generating a simple plot, but if you wish to read further, there are many resources available for you to learn on your own!\n\nR for Data Science (R4DS) - Visualize\nThe grammar of graphics (ggplot2) reference page\n\nIf you’re ever looking for inspiration, here’s a link to a large collection of extensions for making ggplot2 even more powerful as a data visualization tool:\n\nGgplot2 extensions gallery\n\n\n\nTo keep things simple for now, we’ll be using a very simple ggplot to look at the distribution of cases over time. We can easily incorporate this into our summary statement using the pipe operator %&gt;%.\nFor this ggplot, you’ll need to specify the following arguments:\n\naes() - the chart aesthetics (which variables should map to x and y on the chart?)\ngeom_col() - the type of chart that we’d like to produce.\n\nSince we’re already summarizing the data using our summarize() function, we’ll apply a geom_col() layer to visualize the summary as columns. If we were going to let ggplot do the summary for us, we could instead feed our raw data into the function, and use the geom_bar() argument.\nNote that once ggplot has been called, additional layers to the chart must be chained using the + operator, not the %&gt;% operator.\n\n\nsymptoms_manifest %&gt;%\n  group_by(onset.date) %&gt;%\n  count() %&gt;% \n  ggplot(aes(x = onset.date, y = n)) + \n  geom_col()\n\n\n\n\n\n\n\n\nWhile there are many improvements that could be made to this chart, it does confirm our suspicions about the shape of the distribution of cases, this is definitely looking like the ship has experienced a point-source outbreak!\n\n\nFurther exploring the dataset\nLuckily, at this stage, the outbreak appears to be in decline, and may even be over. However, as epidemiologists, we know that if we don’t identify the source of the illnesses, then they could occur again. Using our data-swashbuckling abilities - we have uncovered a number of very strong clues in this scenario so far.\nTake a couple of minutes to summarize, from an epidemiological perspective, what you have learned about the cases and illnesses aboard the S. S. Rainbow Cake so far. This may help to hone your focus on where to investigate next!\n\n\nClick to see the present clues in the investigation\n\nHere’s some of the main considerations so far:\n\nThere is a very strong point-source outbreak signal. We should be thinking about exposures that may have occurred at a single setting (e.g., meals, events).\nWhile all of our cases reported abdominal pain / discomfort, there are some that have reported much more serious symptoms. We may want to investigate these further.\nThere does not appear to be any strong signals based on age and sex of cases.\nWe are on a cruise ship and historically, gastrointestinal outbreaks cause by contaminated food are a common occurrence.\n\n\n\nDifferences in symptoms by onset date\nLet’s go back to our symptoms and see if there are any differences in the symptoms by onset date. This time, we’ll summarize all of different symptoms by date using a clever little function called across().\nThe across() function works within either a mutate() or summarize() call, and allows you to repeat the same operation on a range of variables, rather than having to type them in over and over again. Here, we’ll use it to sum up the number of cases that reported each symptom for each each day in our dataset.\n\n\nsymptoms_manifest %&gt;%\n  group_by(onset.date) %&gt;%\n  summarize(\n    across(\n      c(vomiting, diarrhea, headache, bloody.stool, Fever),\n      ~ sum(.x, na.rm = TRUE)\n      )\n    )\n## # A tibble: 5 × 6\n##   onset.date vomiting diarrhea headache bloody.stool Fever\n##   &lt;date&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n## 1 2025-02-10        3        4        3            1     1\n## 2 2025-02-11       19       21       17            8    11\n## 3 2025-02-12       22       27       24           17    20\n## 4 2025-02-13       10       12        9            5     6\n## 5 2025-02-14        2        2        1            0     0\n\n\n\n\n\n\n\nNote\n\n\n\nDo you notice any differences between the numbers of passengers reporting symptoms? Why might vomiting, diarrhea, and headache be reported less often than the more severe symptoms of bloody stool and fever. What types of gastrointestinal diseases might cause bloody stool and fever?\n\n\n\n\nDifferences in symptoms by other variables\nIf you recall, there are still two variables in our dataset that we haven’t taken a look at yet:\n\nMember Status\nBoarding Date\n\nLet’s leave no stones unturned, and see if we can identify any differences between the passenger’s symptoms and either their cruise-member-status or the day that they boarded the ship. Since bloody stool and fever are definitely the greater cause for concern, we’ll focus on those symptoms only.\n\n\nsymptoms_manifest %&gt;%\n  group_by(`Member Status`) %&gt;%\n  summarize(\n    across(\n      c(bloody.stool, Fever),\n      ~ sum(.x, na.rm = TRUE)\n      )\n    )\n## # A tibble: 3 × 3\n##   `Member Status` bloody.stool Fever\n##   &lt;chr&gt;                  &lt;dbl&gt; &lt;dbl&gt;\n## 1 Gold                       3     6\n## 2 Platinum                   3     4\n## 3 Silver                    25    28\n\n\n\nsymptoms_manifest %&gt;%\n  group_by(`Boarding Date`) %&gt;%\n  summarize(\n    across(\n      c(bloody.stool, Fever),\n      ~ sum(.x, na.rm = TRUE)\n      )\n    )\n## # A tibble: 2 × 3\n##   `Boarding Date`     bloody.stool Fever\n##   &lt;dttm&gt;                     &lt;dbl&gt; &lt;dbl&gt;\n## 1 2025-02-09 00:00:00           31    38\n## 2 2025-02-10 00:00:00            0     0\n\n\n\n\n\n\n\nNote\n\n\n\nWhoa! Did you just crack the outbreak code here!? There definitely looks to be something going on related to the date that passengers boarded the ship, as well as potentially their cruise-member-status.\nExcellent epi-investigative skills!"
  },
  {
    "objectID": "module03.html#summary-and-quiz",
    "href": "module03.html#summary-and-quiz",
    "title": "Module 3",
    "section": "Summary and quiz",
    "text": "Summary and quiz\n\nSummary\nWow! You really covered a lot in this module - give yourself a well-earned pat on the back!\nYou managed to do all of the following, using only tidyverse functions:\n\nJoining multiple datasets using aggregation functions\nJoining multiple datasets using table-joins\nManipulating the shapes of datasets using pivot functions\nSeparating complex strings and creating new variables\nSummarizing data using summary()\nCreating a basic epidemiological curve\nApplying the across() function to summarize with multiple variables at once\n\nThat’s a lot! We even managed to sneak a small preview of regular expressions in there!\n\n\nQuiz\nLet’s do a quick review of the Tidyverse functions we used in this module:\n\n\n\n\n1. You are given five daily abdo_ datasets with identical columns. Which function is most appropriate for combining them into a single dataset by stacking rows?\n\nleft_join(), because it preserves all rows bind_rows(), because the datasets have the same structure pivot_longer(), because it reshapes multiple datasets Submit\n\n\n\n\n\n2. In bind_rows(…, .id = “id”), what does the .id argument capture?\n\nA unique row number for each observation The source dataset each row came from The primary key used for later joins Submit\n\n\n\n\n\n3. Why was skip = 4 used when importing the abdo datasets with read_tsv()?\n\nTo remove the first four rows containing metadata rather than data To skip missing values at the top of the file To improve import speed for large files Submit\n\n\n\n\n\n4. Why was case_when() used instead of if_else() when creating new variables?\n\ncase_when() allows multiple conditional rules to be applied in order case_when() is faster for numeric variables if_else() cannot be used inside mutate() Submit\n\n\n\n\n\n5. Why is it good practice to remove the temporary id variable before joining datasets?\n\nIt reduces file size and improves performance It prevents accidental use of the variable in joins or analyses Joins will fail if extra columns are present Submit\n\n\n\n\n\n6. Why was left_join() used to join the abdo data to the passenger manifest?\n\nTo keep all passengers, even if no abdo record exists To keep only passengers with abdo symptoms Because left_join() automatically removes duplicates Submit\n\n\n\n\n\n7. What problem does by = c(“pass.ID” = “Pass_ID”) solve in a join?\n\nIt converts character IDs to numeric It allows joining on variables with different names It ensures only unique IDs are matched Submit\n\n\n\n\n\n8. What does separate_rows(CEDIS, sep = “;”) do?\n\nSplits a single row into multiple rows based on CEDIS codes Creates new columns for each CEDIS code Removes duplicate CEDIS values Submit\n\n\n\n\n\n9. Why is separate_rows() typically applied before pivot_wider() in this workflow?\n\nTo ensure one value per row before creating indicator columns To reduce the number of columns created To convert character variables into factors Submit\n\n\n\n\n\n10. What assumption does pivot_wider() make about the data when creating new columns?\n\nEach ID–value combination is unique All values are numeric There are no missing values Submit\n\n\n\n\n\n11. If multiple rows exist for the same ID and symptom, which pivot_wider() argument can be used to resolve this?\n\nvalues_fn names_sep id_expand Submit\n\n\n\n\n\n12. What is the primary purpose of using values_fill in pivot_wider()?\n\nTo replace missing combinations with a default value To remove rows with missing data To convert logical values to numeric Submit\n\n\n\n\n\n13. Why is it often useful to create symptom variables as 0/1 indicators?\n\nThey support straightforward summarization and modeling They reduce memory usage in all cases They prevent duplicate rows from occurring Submit\n\n\n\n\n\n14. What advantage does using across() inside summarize() provide?\n\nIt allows the same summary operation to be applied to many variables at once It automatically reshapes the dataset It replaces the need for grouping variables Submit\n\n\n\n\n\n15. Why is inspecting the data with functions like glimpse() important before and after joins?\n\nTo verify structure, variable types, and unexpected changes To permanently modify the dataset To optimize joins for performance Submit"
  }
]